{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afGZVpv4kXC_"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "import json\n",
        "\n",
        "openai.api_key = 'your-openai-api-key'\n",
        "\n",
        "book_files = {\n",
        "    \"book1\": \"/content/book1.txt\",\n",
        "    \"book2\": \"/content/book2.txt\",\n",
        "    \"book3\": \"/content/book3.txt\"\n",
        "}\n",
        "\n",
        "hierarchical_indices = {}\n",
        "for book_name in book_files.keys():\n",
        "    with open(f'hierarchical_index_{book_name}.json', 'r', encoding='utf-8') as f:\n",
        "        hierarchical_indices[book_name] = json.load(f)\n",
        "\n",
        "# Function to extract content from the hierarchical tree\n",
        "def extract_content(node):\n",
        "    if node is None:\n",
        "        return ''\n",
        "\n",
        "    content = node.get('content', '')\n",
        "\n",
        "    for child in node.get('children', []):\n",
        "        child_content = extract_content(child)\n",
        "        if child_content:\n",
        "            content += ' ' + child_content\n",
        "\n",
        "    return content\n",
        "\n",
        "# Extracting content from each book\n",
        "book_contents = {}\n",
        "for book_name, index in hierarchical_indices.items():\n",
        "    book_contents[book_name] = extract_content(index)\n",
        "\n",
        "# Function to answer questions using OpenAI GPT-4\n",
        "def answer_question(book_choice, question):\n",
        "    if book_choice not in book_contents:\n",
        "        return \"Invalid book choice\"\n",
        "\n",
        "    context = book_contents[book_choice]\n",
        "\n",
        "    if not context:\n",
        "        return \"The context for the question is empty.\"\n",
        "\n",
        "    # OpenAI GPT-3.5 to generate a detailed answer\n",
        "    response = openai.Completion.create(\n",
        "        model=\"gpt-3.5-turbo-instruct\t\",\n",
        "        prompt=f\"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer in detail:\",\n",
        "        max_tokens=300\n",
        "    )\n",
        "    answer = response.choices[0].text.strip()\n",
        "    return answer\n",
        "\n",
        "def main():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"## Question Answering with Hierarchical Index\")\n",
        "\n",
        "        book_choice = gr.Dropdown(choices=list(book_files.keys()), label=\"Choose a Book\")\n",
        "        question = gr.Textbox(label=\"Enter your question\")\n",
        "        output = gr.Textbox(label=\"Answer\", interactive=False)\n",
        "\n",
        "        question.submit(fn=answer_question, inputs=[book_choice, question], outputs=output)\n",
        "\n",
        "    demo.launch()\n",
        "\n",
        "main()"
      ]
    }
  ]
}